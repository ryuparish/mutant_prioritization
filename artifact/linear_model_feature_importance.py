from sklearn.inspection import permutation_importance

from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.linear_model import Ridge
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy import sparse
import pandas as pd
import sklearn_pandas
import numpy as np
import matplotlib.pyplot as plt

# Hold out one of these intervals at a time.
# Intervals correspond to the features generated by the mapper.
FEATURE_GROUPS = [
    [0, 159], # mutation operator features (160 features)
    [159, 196], # node type features (37 features)
    [196, 13272], # node/ast context features (13076 features)
    [13272, 13440], # parent context features (168 features)
    [13440, 13443], # child features (3 features)
    [13443, 13450], # nesting features (7 features)
    [13450, 13451], # line ratio feature (1 feature)
]

# Hold out interval names
FEATURE_GROUP_NAMES = [
     "mutation_operator_features",
     "node_type_features",
     "AST_Context_features",
     "parent_Context_features",
     "child_features",
     "nesting_features",
     "lineRatio",
]
        
# Train model with one feature held out.
def hold_out_feature_train(model, X_all, Y_all, X_test, y_test, baseline_score) :
    num_times_sampled = 3
    average_decrease = {}
    
    # Sampling scores
    for sample_num in range(num_times_sampled):
        for feature_group, feature_group_name in zip(FEATURE_GROUPS, FEATURE_GROUP_NAMES):
            print(f"({sample_num})Training while holding out {feature_group_name}...")
            X_without_hold_out = sparse.csc_matrix(X_all.drop(columns=X_all.columns[feature_group[0]:feature_group[1]]))
            X_test_without_hold_out = sparse.csc_matrix(X_test.drop(columns=X_all.columns[feature_group[0]:feature_group[1]]))
            clf = Ridge(solver="sparse_cg", copy_X=False)
            clf.fit(X_without_hold_out, Y_all)
            held_out_score = clf.score(X_test_without_hold_out, y_test)
            if feature_group_name not in average_decrease:
                average_decrease[feature_group_name] = baseline_score - held_out_score
            else:
                average_decrease[feature_group_name] += baseline_score - held_out_score
    
    # Averaging scores
    for feature_group_name in FEATURE_GROUP_NAMES:
        average_decrease[feature_group_name] = average_decrease[feature_group_name] / num_times_sampled
    
    # Printout sorted by value
    sorted_averages = sorted(average_decrease.items(), key=lambda x:x[1], reverse=True)
    print()
    for name, average in sorted_averages:
        print(f"{name} decrease: {average}")

def main():
    print("Creating mapper...")
    mapper = sklearn_pandas.DataFrameMapper(
        [
            (["lineRatio"], [SimpleImputer(strategy="mean"), StandardScaler()]),
            (
                ["nestingIf", "nestingLoop", "nestingTotal", "maxNestingInSameMethod"],
                StandardScaler(),
            ),
            (
                [
                    "nestingRatioLoop",
                    "nestingRatioIf",
                    "nestingRatioTotal",
                    "hasOperatorChild",
                    "hasVariableChild",
                    "hasLiteralChild",
                ],
                None,
            ),
            (
                ["nodeTypeBasic", "nodeTypeDetailed"],
                [
                    SimpleImputer(strategy="constant", fill_value="Unknown"),
                    OneHotEncoder(handle_unknown="ignore"),
                ],
            ),
            (
                [
                    "mutationOperator",
                    "mutationOperatorGroup",
                    "nodeContextBasic",
                    "astContextBasic",
                    "astContextDetailed",
                    "astStmtContextBasic",
                    "astStmtContextDetailed",
                    "parentContextBasic",
                    "parentContextDetailed",
                    "parentStmtContextBasic",
                    "parentStmtContextDetailed",
                ],
                OneHotEncoder(handle_unknown="ignore"),
            ),
        ]
    ,   df_out=True)
    print("Done!")
    
    print("Reading csv...")
    custmut_csv = pd.read_csv("data/all-customized-mutants.csv").sample(frac=0.20, random_state=42)
    print("Done!")
    
    print("Loading/Fitting the data...")
    X, y = mapper.fit_transform(custmut_csv.loc[:, custmut_csv.columns != "pKillDom"]).astype(np.float32), custmut_csv.loc[:, "pKillsDom"].astype(np.float32)
    print("Done!")
    
    print("Splitting the data...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
    print("Done!")
    
    print("Training the model...")
    clf = Ridge(solver="sparse_cg", copy_X=False)
    clf.fit(sparse.csc_matrix(X_train), y_train)
    print("Done!")
    
    print("Getting baseline score...")
    baseline_score = clf.score(X_test, y_test)
    print(f"Baseline accuracy on test data: {baseline_score}")
    print(f"\nHeld-out feature scores:")
    hold_out_feature_train(clf, X_train, y_train, X_test, y_test, baseline_score)

# Python
if __name__ == "__main__":
    main()
